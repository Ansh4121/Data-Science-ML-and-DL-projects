{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFuzLLC4DO7X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load the dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data_train = pd.read_csv('train.csv')\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data_test = pd.read_csv('test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the train data\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "# Separate the features and target variable\n",
        "X_train = train_data.drop('price_range', axis=1)\n",
        "y_train = train_data['price_range']\n",
        "\n",
        "# Check the distribution of variables\n",
        "X_train.hist(bins=50, figsize=(20,15))\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "corr_matrix = X_train.corr()\n",
        "sns.heatmap(corr_matrix, annot=True)\n",
        "plt.show()\n",
        "\n",
        "# Normalize the numerical features using StandardScaler\n",
        "numerical_features = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores',\n",
        "                      'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
        "scaler = StandardScaler()\n",
        "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
        "\n",
        "# One-hot encode the categorical features using OneHotEncoder\n",
        "categorical_features = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_features]))\n",
        "X_train_encoded.columns = encoder.get_feature_names_out(categorical_features)\n",
        "X_train = pd.concat([X_train.drop(categorical_features, axis=1), X_train_encoded], axis=1)\n",
        "\n",
        "# Split the train dataset into training and validation sets\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train and evaluate the logistic regression model\n",
        "logistic_regression_model = LogisticRegression()\n",
        "logistic_regression_model.fit(X_train_split, y_train_split)\n",
        "y_pred_logistic_regression = logistic_regression_model.predict(X_val_split)\n",
        "\n",
        "# Train and evaluate the random forest model\n",
        "random_forest_model = RandomForestClassifier()\n",
        "random_forest_model.fit(X_train_split, y_train_split)\n",
        "y_pred_random_forest = random_forest_model.predict(X_val_split)\n",
        "\n",
        "# Train and evaluate the neural network model\n",
        "neural_network_model = MLPClassifier()\n",
        "neural_network_model.fit(X_train_split, y_train_split)\n",
        "y_pred_neural_network = neural_network_model.predict(X_val_split)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "logistic_regression_accuracy = accuracy_score(y_val_split, y_pred_logistic_regression)\n",
        "random_forest_accuracy = accuracy_score(y_val_split, y_pred_random_forest)\n",
        "neural_network_accuracy = accuracy_score(y_val_split, y_pred_neural_network)\n",
        "\n",
        "logistic_regression_precision = precision_score(y_val_split, y_pred_logistic_regression, average='weighted')\n",
        "random_forest_precision = precision_score(y_val_split, y_pred_random_forest, average='weighted')\n",
        "neural_network_precision = precision_score(y_val_split, y_pred_neural_network, average='weighted')\n",
        "\n",
        "logistic_regression_recall = recall_score(y_val_split, y_pred_logistic_regression, average='weighted')\n",
        "random_forest_recall = recall_score(y_val_split, y_pred_random_forest, average='weighted')\n",
        "neural_network_recall = recall_score(y_val_split, y_pred_neural_network, average='weighted')\n",
        "\n",
        "logistic_regression_f1_score = f1_score(y_val_split, y_pred_logistic_regression, average='weighted')\n",
        "random_forest_f1_score = f1_score(y_val_split, y_pred_random_forest, average='weighted')\n",
        "neural_network_f1_score = f1_score(y_val_split, y_pred_neural_network, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics for each model\n",
        "models = ['Logistic Regression', 'Random Forest', 'Neural Network']\n",
        "accuracy = [logistic_regression_accuracy, random_forest_accuracy, neural_network_accuracy]\n",
        "precision = [logistic_regression_precision, random_forest_precision, neural_network_precision]\n",
        "recall = [logistic_regression_recall, random_forest_recall, neural_network_recall]\n",
        "f1_score = [logistic_regression_f1_score, random_forest_f1_score, neural_network_f1_score]\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"{models[i]} Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy[i])\n",
        "    print(\"Precision:\", precision[i])\n",
        "    print(\"Recall:\", recall[i])\n",
        "    print(\"F1 Score:\", f1_score[i])\n",
        "    print()\n",
        "\n",
        "# Plot feature importances for models that have this attribute (e.g., Random Forest)\n",
        "if hasattr(random_forest_model, 'feature_importances_'):\n",
        "    importances = random_forest_model.feature_importances_\n",
        "    indices = np.argsort(importances)\n",
        "    features = X_train.columns\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.title('Feature Importances')\n",
        "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "    plt.xlabel('Relative Importance')\n",
        "    plt.show()\n",
        "\n",
        "coefficients = logistic_regression_model.coef_[0]\n",
        "coefficients = pd.Series(coefficients, index=X_train.columns)\n",
        "coefficients = coefficients.sort_values(ascending=False)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title('Feature Importance (Logistic Regression)')\n",
        "coefficients.plot(kind=\"bar\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Get importance\n",
        "importance = permutation_importance(neural_network_model, X_val_split, y_val_split, scoring='accuracy', n_repeats=5, random_state=42)\n",
        "# summarize feature importance\n",
        "importances = importance.importances_mean\n",
        "indices = np.argsort(importances)\n",
        "features = X_train.columns\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title('Feature Importance (Neural Network)')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Mean Importance')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "axjJ3xQVRBCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Further steps with the test set and making predictions...\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the validation set using the trained models\n",
        "y_pred_logistic_regression_val = logistic_regression_model.predict(X_val_split)\n",
        "y_pred_random_forest_val = random_forest_model.predict(X_val_split)\n",
        "y_pred_neural_network_val = neural_network_model.predict(X_val_split)\n",
        "\n",
        "# Create confusion matrices for each model\n",
        "cm_logistic_regression = confusion_matrix(y_val_split, y_pred_logistic_regression_val)\n",
        "cm_random_forest = confusion_matrix(y_val_split, y_pred_random_forest_val)\n",
        "cm_neural_network = confusion_matrix(y_val_split, y_pred_neural_network_val)\n",
        "\n",
        "# Define the class labels\n",
        "class_labels = ['Low', 'Medium', 'High', 'Very High']\n",
        "\n",
        "# Plot confusion matrices using seaborn\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Logistic Regression Confusion Matrix\n",
        "sns.heatmap(cm_logistic_regression, annot=True, fmt=\".2f\", linewidths=.5, square=True, cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels, ax=axes[0])\n",
        "axes[0].set_xlabel('Predicted label')\n",
        "axes[0].set_ylabel('Actual label')\n",
        "axes[0].set_title('Confusion Matrix for Logistic Regression Model')\n",
        "\n",
        "# Random Forest Confusion Matrix\n",
        "sns.heatmap(cm_random_forest, annot=True, fmt=\".2f\", linewidths=.5, square=True, cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels, ax=axes[1])\n",
        "axes[1].set_xlabel('Predicted label')\n",
        "axes[1].set_ylabel('Actual label')\n",
        "axes[1].set_title('Confusion Matrix for Random Forest Model')\n",
        "\n",
        "# Neural Network Confusion Matrix\n",
        "sns.heatmap(cm_neural_network, annot=True, fmt=\".2f\", linewidths=.5, square=True, cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels, ax=axes[2])\n",
        "axes[2].set_xlabel('Predicted label')\n",
        "axes[2].set_ylabel('Actual label')\n",
        "axes[2].set_title('Confusion Matrix for Neural Network Model')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IUQ29YtcENoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Evaluate the models using cross-validation\n",
        "logistic_regression_cv_scores = cross_val_score(logistic_regression_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "random_forest_cv_scores = cross_val_score(random_forest_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "neural_network_cv_scores = cross_val_score(neural_network_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Logistic Regression Cross-Validation Scores:\")\n",
        "print(logistic_regression_cv_scores)\n",
        "print(\"Mean Accuracy:\", logistic_regression_cv_scores.mean())\n",
        "print()\n",
        "\n",
        "print(\"Random Forest Cross-Validation Scores:\")\n",
        "print(random_forest_cv_scores)\n",
        "print(\"Mean Accuracy:\", random_forest_cv_scores.mean())\n",
        "print()\n",
        "\n",
        "print(\"Neural Network Cross-Validation Scores:\")\n",
        "print(neural_network_cv_scores)\n",
        "print(\"Mean Accuracy:\", neural_network_cv_scores.mean())\n",
        "print()\n"
      ],
      "metadata": {
        "id": "Pce-ksHFSQdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Box plots for each numeric variable\n",
        "plt.figure(figsize=(20,10))\n",
        "X_train[numerical_features].boxplot()\n",
        "plt.title(\"Box plots for each numeric variable\")\n",
        "plt.show()\n",
        "\n",
        "# Pair plots\n",
        "sns.pairplot(X_train[numerical_features])\n",
        "plt.show()\n",
        "\n",
        "# ROC Curves for Model Evaluation\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def plot_roc_curve(y_true, y_pred, model_name):\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_true)\n",
        "    y_true = lb.transform(y_true)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(y_true.shape[1]):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"macro\"], tpr[\"macro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
        "    roc_auc[\"macro\"] = roc_auc_score(y_true, y_pred, average='micro')\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]))\n",
        "    for i in range(y_true.shape[1]):\n",
        "        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic for {}'.format(model_name))\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_curve(y_val_split, y_pred_logistic_regression, 'Logistic Regression')\n",
        "plot_roc_curve(y_val_split, y_pred_random_forest, 'Random Forest')\n",
        "plot_roc_curve(y_val_split, y_pred_neural_network, 'Neural Network')\n",
        "\n",
        "    # 1)Box plots for each numeric variable: This will help you to visualize the distribution, median and outliers for each numeric variable.\n",
        "\n",
        "    # 2)Pair plots: This will help you to visualize the relationship between each pair of numeric variables.\n",
        "\n",
        "    # 3) ROC Curves for Model Evaluation: You can plot the receiver operating characteristic (ROC) curves of each model in the same plot.\n",
        "    #    The area under the ROC curve (AUC-ROC) can be used as a metric to compare the performance of the models."
      ],
      "metadata": {
        "id": "NeVW2yk9eGjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Loading test data\n",
        "data_test = pd.read_csv('test.csv')\n",
        "\n",
        "# Separate the features in the test dataset (dropping 'id' as it's not a feature)\n",
        "X_test = data_test.drop('id', axis=1)\n",
        "\n",
        "# ... Rest of the preprocessing steps ...\n",
        "\n",
        "# Normalize numerical features\n",
        "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
        "\n",
        "# One-hot encode categorical features\n",
        "X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_features]))\n",
        "X_test_encoded.columns = encoder.get_feature_names_out(categorical_features)\n",
        "X_test = pd.concat([X_test.drop(categorical_features, axis=1), X_test_encoded], axis=1)\n",
        "\n",
        "# Make predictions using the trained models\n",
        "logistic_regression_predictions = logistic_regression_model.predict(X_test)\n",
        "random_forest_predictions = random_forest_model.predict(X_test)\n",
        "neural_network_predictions = neural_network_model.predict(X_test)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Logistic Regression Predictions:\")\n",
        "print(logistic_regression_predictions)\n",
        "\n",
        "print(\"Random Forest Predictions:\")\n",
        "print(random_forest_predictions)\n",
        "\n",
        "print(\"Neural Network Predictions:\")\n",
        "print(neural_network_predictions)\n",
        "# Make predictions on the validation set using the trained models\n",
        "y_pred_logistic_regression_val = logistic_regression_model.predict(X_val_split)\n",
        "y_pred_random_forest_val = random_forest_model.predict(X_val_split)\n",
        "y_pred_neural_network_val = neural_network_model.predict(X_val_split)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Logistic Regression Predictions for Validation Set:\")\n",
        "print(y_pred_logistic_regression_val)\n",
        "\n",
        "print(\"Random Forest Predictions for Validation Set:\")\n",
        "print(y_pred_random_forest_val)\n",
        "\n",
        "print(\"Neural Network Predictions for Validation Set:\")\n",
        "print(y_pred_neural_network_val)\n"
      ],
      "metadata": {
        "id": "j4SVi9u-rAlO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}